{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as scio\n",
    "import numpy as np\n",
    "\n",
    "dataFile=('mnist_data.mat')\n",
    "\n",
    "data=scio.loadmat(dataFile) # read the dataset\n",
    "\n",
    "data.items() # show values in dataset\n",
    "\n",
    "# begin to extract features for both training set and testing set.\n",
    "xTrain=data['trX'] # give the training set as xTrain\n",
    "\n",
    "yTrain=data['trY']  # give the training dataset label as yTrain\n",
    "yTrain_label = np.reshape(yTrain, (-1, yTrain.shape[0]))\n",
    "\n",
    "p7 = 6265/(6265+5851) # get the priority probability of digit 7 and 8\n",
    "p8 = 5851/(6265+5851)\n",
    "\n",
    "xTest=data['tsX'] # give the testing dataset as xTest\n",
    "\n",
    "xTest_mean = np.mean(xTest,1) # extract feature from test dataset\n",
    "xTest_std = np.std(xTest,1)\n",
    "xTrain_mean = np.mean(xTrain,1)\n",
    "xTrain_std = np.std(xTrain,1)\n",
    "\n",
    "xTrain_7=xTrain[:6265,:] # give the 0-6265 row as images 7\n",
    "xTrain_8=xTrain[6265:,:] # give the 6265-end row as images 8\n",
    "\n",
    "# extract the feature of 7s in training dataset\n",
    "xTrain_7mean=np.mean(xTrain_7,axis=1) \n",
    "xTrain_7std=np.std(xTrain_7,axis=1)\n",
    "\n",
    "# extract the feature of 8s in training dataset\n",
    "xTrain_8mean=np.mean(xTrain_8,axis=1)  \n",
    "xTrain_8std=np.std(xTrain_8,axis=1)\n",
    "\n",
    "# implement the Naive Bayes Classifier and use it produce a predicted label for each testing sample.\n",
    "# write the pdf formula\n",
    "import math     \n",
    "def pdf(t1,t2,m1,m2,s1,s2):\n",
    "    exponent = math.exp(-(1/2) * (( math.pow(t1 - m1, 2) / (s1 * s1)) + (math.pow(t2 - m2, 2) / (s2 *s2))))\n",
    "    return  1 / (2 * math.pi * s1 * s2) * exponent\n",
    "\n",
    "# use MLE density Estimation to get each feature`s mean and\n",
    "# standard deviation for both 7 and 8 digtis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Digit seven`s two features` means and stds: 0.11452769775108769 0.03063240469648838 0.28755656517748474 0.038201083694320306\n",
      "Digit eight`s two features` means and stds: 0.15015598189369758 0.038632488373958954 0.3204758364888714 0.039960074370658606\n"
     ]
    }
   ],
   "source": [
    "seven_m1=np.mean(xTrain_7mean) \n",
    "seven_s1=np.std(xTrain_7mean)  \n",
    "seven_m2=np.mean(xTrain_7std)\n",
    "seven_s2=np.std(xTrain_7std)\n",
    "eight_m1=np.mean(xTrain_8mean)\n",
    "eight_s1=np.std(xTrain_8mean)\n",
    "eight_m2=np.mean(xTrain_8std)\n",
    "eight_s2=np.std(xTrain_8std)\n",
    "print (\"Digit seven`s two features` means and stds:\",seven_m1,seven_s1,seven_m2,seven_s2)\n",
    "print (\"Digit eight`s two features` means and stds:\",eight_m1,eight_s1,eight_m2,eight_s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The  Naïve Bayes classification accuracy of 7: 0.7597276264591439\n",
      "The  Naïve Bayes classification accuracy of 8: 0.6273100616016427\n",
      "The  Naïve Bayes classification accuracy of both 7 and 8: 0.6953046953046953\n",
      "The Logistic Regression classification accuracy of 7: 0.796692607003891\n",
      "The Logistic Regression classification accuracy of 8: 0.6796714579055442\n",
      "The Logistic Regression classification accuracy of both 7 and 8: 0.7397602397602397\n"
     ]
    }
   ],
   "source": [
    "# predict the result by compare p1 and p2, p1 and p2 are the value of result from apply \n",
    "# two features from test dataset * priority of two digits.\n",
    "predict_test = [0 for x in range(xTest.shape[0])] \n",
    "for i in range(xTest.shape[0]):                   \n",
    "    p1 = pdf(xTest_mean[i], xTest_std[i], seven_m1, seven_m2, seven_s1, seven_s2) * p7\n",
    "    p2 = pdf(xTest_mean[i], xTest_std[i], eight_m1, eight_m2, eight_s1, eight_s2) * p8\n",
    "    if p1>p2:\n",
    "        predict_test[i] = 0\n",
    "    else:\n",
    "        predict_test[i] = 1\n",
    "\n",
    "# Report the classification accuracy for \"7\" in the testing set.\n",
    "print(\"The  Naïve Bayes classification accuracy of 7:\",predict_test[:1028].count(0)/1028)\n",
    "\n",
    "# Report the classification accuracy for \"8\" in the testing set.\n",
    "print (\"The  Naïve Bayes classification accuracy of 8:\",predict_test[1028:].count(1)/974)\n",
    "\n",
    "# compute the classification accuracy\n",
    "# Get the accuracy of how many correct prediction of digits 7 and 8 from test dataset\n",
    "print (\"The  Naïve Bayes classification accuracy of both 7 and 8:\",(predict_test[:1028].count(0)+predict_test[1028:].count(1))/(xTest.shape[0])) \n",
    "\n",
    "# implement the Logistic Regression and use it produce a predicted label for each testing sample.\n",
    "# define sigmoid formula\n",
    "def sigmoid (x):\n",
    "    return 1./(1+np.exp(-x))\n",
    "\n",
    "# combine mean and std as 2D matrix named datamatrix\n",
    "datamatrix=np.column_stack((xTrain_mean,xTrain_std))\n",
    "\n",
    "# define how grad_ascent works, use sigmoid formula to calculate thetas\n",
    "def grad_ascent(datamatrix,yTrain_label,lr,cycles):\n",
    "    datamatrix=np.mat(datamatrix)\n",
    "    labels=np.mat(yTrain_label)\n",
    "    thetas=np.ones((2,1)) # initital theta\n",
    "    t_matrix=datamatrix.transpose()\n",
    "    for k in range(cycles):\n",
    "        h=sigmoid(datamatrix*thetas)\n",
    "        thetas=thetas+lr*t_matrix*(labels-h)\n",
    "    return thetas\n",
    "\n",
    "# set up learning rate and repeate times when applying testmatrix\n",
    "thetas= grad_ascent(datamatrix,yTrain_label,0.001,10000)\n",
    "#make a testmatrix to combine mean and std in Test set\n",
    "testmatrix=np.column_stack((xTest_mean,xTest_std))\n",
    "result=sigmoid(testmatrix*thetas)\n",
    "\n",
    "# to compare the result of prediction, if it less than 0.5 returen 0, else return 1\n",
    "predict=[0 for x in range(xTest.shape[0])]\n",
    "for i in range(result.shape[0]):\n",
    "    if result[i]>0.5:\n",
    "        predict[i]=1\n",
    "    else:\n",
    "        predict[i]=0\n",
    "\n",
    "# Report the classification accuracy for \"7\" in the testing set.\n",
    "print(\"The Logistic Regression classification accuracy of 7:\",predict[:1028].count(0)/1028)\n",
    "\n",
    "# Report the classification accuracy for \"8\" in the testing set.\n",
    "print (\"The Logistic Regression classification accuracy of 8:\",predict[1028:].count(1)/974)\n",
    "\n",
    "# compute the classification accuracy of both \"7\" and \"8\" in the testing set\n",
    "print (\"The Logistic Regression classification accuracy of both 7 and 8:\",(predict[:1028].count(0)+predict[1028:].count(1))/(xTest.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
